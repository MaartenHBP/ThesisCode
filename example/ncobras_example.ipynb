{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Example\n",
    "## Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Projecten\\Unif_proj\\ThesisCode\\example\\iris.data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from noise_robust_cobras.cobras import COBRAS\n",
    "from noise_robust_cobras.querier.noisy_labelquerier import ProbabilisticNoisyQuerier\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = Path('iris.data').absolute()\n",
    "assert dataset_path.exists(), f\"the dataset does not exist here the root path is {Path().absolute()}\"\n",
    "\n",
    "querier_seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's start of with loading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (147, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt(dataset_path, delimiter=',')\n",
    "data = dataset[:, 1:]\n",
    "target = dataset[:, 0]\n",
    "print(f\"data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a noisy oracle to simulate a domain expert that makes some mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noisy_querier = ProbabilisticNoisyQuerier(None, target, 0.1,100, random_seed=querier_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a COBRAS object to cluster the data based on the supervision that the noisy querier gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clusterer = COBRAS(noise_probability=0.1,minimum_approximation_order=3, maximum_approximation_order=6)\n",
    "# only store the first two return values\n",
    "all_clusters, runtimes, *_ = clusterer.fit(data, -1, None, noisy_querier)\n",
    "best_clustering_robust = all_clusters[-1]\n",
    "runtime_robust = runtimes[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Evaluate the clustering quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering took 32.644, ARI = 0.882\n"
     ]
    }
   ],
   "source": [
    "ARI_score_robust = adjusted_rand_score(target, best_clustering_robust)\n",
    "print(f\"Clustering took {runtime_robust:0.3f}, ARI = {ARI_score_robust:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For reference also run cobras with no noise handling mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering took 1.092, ARI = 0.482\n"
     ]
    }
   ],
   "source": [
    "# make a new querier (take care these are statefull! so make a new querier every time)\n",
    "noisy_querier = ProbabilisticNoisyQuerier(None, target, 0.1,100, random_seed=querier_seed)\n",
    "\n",
    "# make new COBRAS\n",
    "clusterer = COBRAS(correct_noise=False)\n",
    "all_clusters, runtimes, *_ = clusterer.fit(data, -1, None, noisy_querier)\n",
    "best_clustering = all_clusters[-1]\n",
    "runtime = runtimes[-1]\n",
    "\n",
    "ARI_score = adjusted_rand_score(target, best_clustering)\n",
    "print(f\"Clustering took {runtime:0.3f}, ARI = {ARI_score:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So as you can see nCOBRAS performs significantly better than COBRAS in the presence of noise.\n",
    "However, the reasoning about noisy constraints takes time and thus nCOBRAS is also considerably slower than COBRAS.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "995406004189bc7a762cd15e0adc766b4032076a3e0cf164ca390850079b6fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
